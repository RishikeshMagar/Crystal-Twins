batch_size: 512
epochs: 15
eval_every_n_epochs: 1
fine_tune_from: None
log_every_n_steps: 50
weight_decay: 1e-6
fp16_precision: False
init_lr: 0.0005
gpu: cuda:0

model: 
  num_layer: 5
  emb_dim: 256
  feat_dim: 1024
  JK: last
  drop_ratio: 0

dataset:
  num_workers: 8
  valid_size: 0.05
  data_dir: matminer
  k: 12
  atom_mask: 0.1
  edge_mask: 0.1
  
loss:
  embed_size: 256
  lambd: 0.0051

